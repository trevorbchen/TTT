# CBG (Classifier-Based Guidance) training defaults

# Architecture
base_channels: 64
channel_mult: [1, 2, 4, 4]
emb_dim: 256
attn_heads: 4
y_channels: 4  # spatial channels for MeasurementEncoder (non-image obs)
decoder_hidden: 512   # hidden dim for MeasurementDecoder MLP
num_res_blocks: 1     # ResBlocks per encoder/decoder level (2 = deeper)
num_tokens: 0         # cross-attention tokens (0 = off, 64 = recommended)

# Training
lr: 1e-4
weight_decay: 1e-4
grad_clip: 10.0

# Sequential sigma training (TTT-style):
#   For each sample, iterate through ALL sigma levels (single pass).
num_sigma_steps: 200    # number of discrete VP sigma levels
sigma_batch_size: 8     # sigma levels batched per optimizer step
num_passes: 1           # passes through the dataset
val_every_steps: 500    # validate every N optimizer steps
save_every_steps: 2000  # checkpoint every N steps

# Min-SNR-gamma loss weighting (Kingma/Hang et al.)
#   Upweights low-noise (fine detail) steps, downweights high-noise (coarse).
#   w(sigma) = min(1/sigma^2, gamma). Set 0 to disable.
snr_gamma: 5.0

# Data
train_pct: 10
val_fraction: 0.1

# Target
target_mode: tweedie    # "tweedie" or "direct"
normalize_target: true

# Output
save_dir: exps/cbg
